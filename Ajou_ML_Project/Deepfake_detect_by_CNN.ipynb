{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VjLtQB53XeH",
        "outputId": "a2ccdd15-86df-4e33-8848-c8212505c2be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BFnb6s93xVL",
        "outputId": "6e4ce793-0590-4f40-b0e7-e8159a8512a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "YXIGfYWiKNk8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive에 있는 훈련, 검증, 테스트 데이터셋의 경로를 지정합니다\n",
        "train_dir = '/content/drive/MyDrive/dataset/train'\n",
        "test_dir = '/content/drive/MyDrive/dataset/test'\n",
        "validation_dir = '/content/drive/MyDrive/dataset/validation'"
      ],
      "metadata": {
        "id": "J07b1QVX2ZZ8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지를 0에서 1 사이의 값으로 정규화하는 함수를 정의합니다\n",
        "def normalize_image(image, labels):\n",
        "  image = tf.cast(image, tf.float32) / 255.0\n",
        "  return image, labels"
      ],
      "metadata": {
        "id": "AzpxgYgt2-at"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 지정된 디렉토리에서 이미지 데이터셋을 로드하고, 이미지를 256x256 픽셀로 리사이즈하며, 라벨을 범주형 형식으로 지정합니다.\n",
        "\n",
        "IMG_SIZE = (256, 256)\n",
        "\n",
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                 label_mode = 'categorical',\n",
        "                                                                 batch_size = 32,\n",
        "                                                                 image_size= IMG_SIZE)\n",
        "\n",
        "validation_data = tf.keras.preprocessing.image_dataset_from_directory(validation_dir,\n",
        "                                                                 label_mode = 'categorical',\n",
        "                                                                 batch_size = 32,\n",
        "                                                                 image_size= IMG_SIZE)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                 label_mode = 'categorical',\n",
        "                                                                 batch_size = 32,\n",
        "                                                                 image_size= IMG_SIZE,\n",
        "                                                                shuffle = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH_DDxI83BDX",
        "outputId": "862b46d1-97be-4c3c-8f88-8d53e4d6cf35"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6011 files belonging to 2 classes.\n",
            "Found 2010 files belonging to 2 classes.\n",
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 그런 다음 정의된 함수로 데이터를 정규화합니다\n",
        "\n",
        "train_data = train_data.map(normalize_image)\n",
        "validation_data = validation_data.map(normalize_image)\n",
        "test_data = test_data.map(normalize_image)"
      ],
      "metadata": {
        "id": "i6p-to7j3LA9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keras Sequential API를 사용하여 CNN 모델을 정의합니다. 모델 아키텍처는 Convolution layer, Maxpooling layer, Batch Normalization, Dropout을 포함합니다. 마지막 레이어는 소프트맥스 활성화를 사용하여 다중 클래스 분류를 수행합니다\n",
        "# Model은 이 데이터를 이용하여 먼저 분류를 해보신 분의 CNN 모델을 참고하였습니다. 이 사람은 512개의 filter로 한 것은 사용하지 않고 주석처리로 남겨놨는데, 아마도 학습 시간이 너무 오래걸려서가 아닐까 생각해봅니다..\n",
        "\n",
        "model_CNN = Sequential([\n",
        "\n",
        "    # Conv2D(filters = 512 , kernel_size=3, padding = 'valid', input_shape = (256, 256, 3), activation= 'relu'),\n",
        "    # tf.keras.layers.MaxPooling2D(),\n",
        "    # tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    Conv2D(filters = 8, kernel_size = 5,input_shape = (256, 256, 3), activation= 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    Conv2D(filters= 16, kernel_size=4, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    Conv2D(filters= 32, kernel_size=3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    Conv2D(filters= 64, kernel_size=2, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    Conv2D(filters= 128, kernel_size=1, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    Flatten(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    Dense(units = 64, activation = 'softmax'),\n",
        "    Dense(units = 20, activation = 'softmax'),\n",
        "    Dense(units = 2, activation = 'softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "0VQC7SM_3YnP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam optimizer, Binary Cross entropy function, accuracy를 평가 지표로 사용하여 모델을 컴파일합니다\n",
        "\n",
        "model_CNN.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "                loss = 'BinaryCrossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ZdRBglHA3kVz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train data를 사용하여 모델을 50번의 epochs 동안 train 시키고, validation data를 사용하여 검증합니다\n",
        "\n",
        "hist = model_CNN.fit(train_data,\n",
        "                    epochs = 50,\n",
        "                    validation_data = validation_data,\n",
        "                    validation_steps = int(0.5 * len(validation_data))\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoFo-hX53nxA",
        "outputId": "c718a606-c7de-4c65-8706-ce3a631426be"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "188/188 [==============================] - 1760s 9s/step - loss: 0.6454 - accuracy: 0.7505 - val_loss: 0.6155 - val_accuracy: 0.7560\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 27s 139ms/step - loss: 0.5880 - accuracy: 0.7505 - val_loss: 0.5653 - val_accuracy: 0.7601\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 26s 135ms/step - loss: 0.5573 - accuracy: 0.7505 - val_loss: 0.5395 - val_accuracy: 0.7581\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.5329 - accuracy: 0.7505 - val_loss: 0.5194 - val_accuracy: 0.7540\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.5100 - accuracy: 0.7505 - val_loss: 0.5099 - val_accuracy: 0.7621\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 27s 137ms/step - loss: 0.4941 - accuracy: 0.7505 - val_loss: 0.5055 - val_accuracy: 0.7581\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 26s 133ms/step - loss: 0.4842 - accuracy: 0.7505 - val_loss: 0.4720 - val_accuracy: 0.7641\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 28s 144ms/step - loss: 0.4625 - accuracy: 0.7505 - val_loss: 0.4206 - val_accuracy: 0.7510\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 30s 154ms/step - loss: 0.4676 - accuracy: 0.7505 - val_loss: 0.4230 - val_accuracy: 0.7560\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 28s 146ms/step - loss: 0.4505 - accuracy: 0.7774 - val_loss: 0.4077 - val_accuracy: 0.8347\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 29s 148ms/step - loss: 0.4307 - accuracy: 0.7955 - val_loss: 0.4108 - val_accuracy: 0.8397\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 27s 139ms/step - loss: 0.4309 - accuracy: 0.8062 - val_loss: 0.4067 - val_accuracy: 0.8498\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 28s 143ms/step - loss: 0.4387 - accuracy: 0.7937 - val_loss: 0.4130 - val_accuracy: 0.8145\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 28s 143ms/step - loss: 0.4297 - accuracy: 0.8042 - val_loss: 0.3831 - val_accuracy: 0.8347\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.3975 - accuracy: 0.8336 - val_loss: 0.4036 - val_accuracy: 0.8175\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 27s 137ms/step - loss: 0.4048 - accuracy: 0.8220 - val_loss: 0.3898 - val_accuracy: 0.8317\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 27s 140ms/step - loss: 0.4004 - accuracy: 0.8193 - val_loss: 0.3794 - val_accuracy: 0.8478\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.3958 - accuracy: 0.8128 - val_loss: 0.4176 - val_accuracy: 0.8054\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 26s 133ms/step - loss: 0.3822 - accuracy: 0.8296 - val_loss: 0.3637 - val_accuracy: 0.8700\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 26s 135ms/step - loss: 0.3753 - accuracy: 0.8361 - val_loss: 0.4347 - val_accuracy: 0.8105\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.3742 - accuracy: 0.8358 - val_loss: 0.4873 - val_accuracy: 0.7550\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 27s 140ms/step - loss: 0.3717 - accuracy: 0.8350 - val_loss: 0.4028 - val_accuracy: 0.8357\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.3536 - accuracy: 0.8469 - val_loss: 0.4000 - val_accuracy: 0.8488\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 28s 145ms/step - loss: 0.3500 - accuracy: 0.8586 - val_loss: 0.3835 - val_accuracy: 0.8558\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.3483 - accuracy: 0.8543 - val_loss: 0.4010 - val_accuracy: 0.8438\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.3469 - accuracy: 0.8543 - val_loss: 0.3858 - val_accuracy: 0.8337\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 26s 137ms/step - loss: 0.3379 - accuracy: 0.8608 - val_loss: 0.4257 - val_accuracy: 0.8296\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 27s 140ms/step - loss: 0.3445 - accuracy: 0.8594 - val_loss: 0.3748 - val_accuracy: 0.8498\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 26s 133ms/step - loss: 0.3271 - accuracy: 0.8654 - val_loss: 0.4109 - val_accuracy: 0.8135\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 26s 133ms/step - loss: 0.3217 - accuracy: 0.8659 - val_loss: 0.3972 - val_accuracy: 0.8528\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 26s 131ms/step - loss: 0.3179 - accuracy: 0.8677 - val_loss: 0.4057 - val_accuracy: 0.8236\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 28s 143ms/step - loss: 0.3166 - accuracy: 0.8709 - val_loss: 0.4020 - val_accuracy: 0.8175\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 26s 134ms/step - loss: 0.3267 - accuracy: 0.8654 - val_loss: 0.3558 - val_accuracy: 0.8538\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 26s 135ms/step - loss: 0.3111 - accuracy: 0.8777 - val_loss: 0.3688 - val_accuracy: 0.8478\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 27s 139ms/step - loss: 0.3350 - accuracy: 0.8626 - val_loss: 0.3900 - val_accuracy: 0.8276\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 28s 142ms/step - loss: 0.3068 - accuracy: 0.8787 - val_loss: 0.4180 - val_accuracy: 0.8306\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 27s 143ms/step - loss: 0.3220 - accuracy: 0.8669 - val_loss: 0.3968 - val_accuracy: 0.8327\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 27s 139ms/step - loss: 0.2919 - accuracy: 0.8859 - val_loss: 0.4326 - val_accuracy: 0.8448\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 27s 139ms/step - loss: 0.3246 - accuracy: 0.8651 - val_loss: 0.4495 - val_accuracy: 0.8085\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 32s 168ms/step - loss: 0.3296 - accuracy: 0.8659 - val_loss: 0.3953 - val_accuracy: 0.8468\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 27s 142ms/step - loss: 0.3064 - accuracy: 0.8741 - val_loss: 0.4282 - val_accuracy: 0.8286\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 27s 142ms/step - loss: 0.2999 - accuracy: 0.8812 - val_loss: 0.4154 - val_accuracy: 0.8236\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 27s 138ms/step - loss: 0.2941 - accuracy: 0.8820 - val_loss: 0.3715 - val_accuracy: 0.8498\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 27s 138ms/step - loss: 0.3052 - accuracy: 0.8772 - val_loss: 0.3513 - val_accuracy: 0.8569\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 26s 137ms/step - loss: 0.2930 - accuracy: 0.8824 - val_loss: 0.4270 - val_accuracy: 0.8427\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 27s 141ms/step - loss: 0.2787 - accuracy: 0.8892 - val_loss: 0.3789 - val_accuracy: 0.8468\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 28s 142ms/step - loss: 0.2797 - accuracy: 0.8869 - val_loss: 0.4470 - val_accuracy: 0.8377\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 27s 138ms/step - loss: 0.3157 - accuracy: 0.8739 - val_loss: 0.4186 - val_accuracy: 0.8306\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 26s 133ms/step - loss: 0.3053 - accuracy: 0.8756 - val_loss: 0.4493 - val_accuracy: 0.8034\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 26s 132ms/step - loss: 0.2919 - accuracy: 0.8782 - val_loss: 0.4108 - val_accuracy: 0.8306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련된 모델을 test data로 평가하여 성능을 확인합니다\n",
        "\n",
        "model_CNN.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLFXtRiI3pqc",
        "outputId": "560ee76c-4267-4630-db9b-dbd7e39bfd5d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 514s 8s/step - loss: 0.4629 - accuracy: 0.8050\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.462939977645874, 0.8050000071525574]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10000개의 data를 train : validation : test = 6 : 2 : 2의 비율로 나눠 CNN을 한 결과, 정확도는 약 80% 정도로 10000개의 DATA로만 해도 상당히 높은 정확도를 보이고 있습니다."
      ],
      "metadata": {
        "id": "_JxgHVw2nK4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# F1 score로도 평가해보기 위해 f1 score 함수를 정의했습니다.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1 - y_true) * (1 - y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float'), axis=0)\n",
        "\n",
        "    precision = tp / (tp + fp + K.epsilon())\n",
        "    recall = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return K.mean(f1)\n"
      ],
      "metadata": {
        "id": "03c4yF4wTYTa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F1 score를 평가 지표로 추가했습니다\n",
        "\n",
        "model_CNN.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "                loss = 'BinaryCrossentropy',\n",
        "                metrics=['accuracy', f1_score])"
      ],
      "metadata": {
        "id": "O7CQCE_5YhBE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 지표를 추가하였으니 다시 fitting을 합니다\n",
        "\n",
        "hist = model_CNN.fit(train_data,\n",
        "                    epochs = 50,\n",
        "                    validation_data = validation_data,\n",
        "                    validation_steps = int(0.5 * len(validation_data))\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MrBX-OIYkjD",
        "outputId": "d59fe9ca-4af3-4002-d0c2-a0b9729fc9f7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "188/188 [==============================] - 30s 128ms/step - loss: 0.2822 - accuracy: 0.8869 - f1_score: 0.8290 - val_loss: 0.4221 - val_accuracy: 0.8216 - val_f1_score: 0.6851\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 24s 123ms/step - loss: 0.2678 - accuracy: 0.8937 - f1_score: 0.8431 - val_loss: 0.3911 - val_accuracy: 0.8448 - val_f1_score: 0.7438\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 25s 127ms/step - loss: 0.2807 - accuracy: 0.8907 - f1_score: 0.8385 - val_loss: 0.4171 - val_accuracy: 0.8367 - val_f1_score: 0.7088\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.2815 - accuracy: 0.8902 - f1_score: 0.8392 - val_loss: 0.3854 - val_accuracy: 0.8508 - val_f1_score: 0.7524\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 24s 123ms/step - loss: 0.2847 - accuracy: 0.8885 - f1_score: 0.8415 - val_loss: 0.4462 - val_accuracy: 0.8448 - val_f1_score: 0.7524\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.2837 - accuracy: 0.8929 - f1_score: 0.8398 - val_loss: 0.4880 - val_accuracy: 0.8367 - val_f1_score: 0.7196\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 30s 158ms/step - loss: 0.2811 - accuracy: 0.8935 - f1_score: 0.8410 - val_loss: 0.4361 - val_accuracy: 0.8276 - val_f1_score: 0.6722\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 24s 124ms/step - loss: 0.2765 - accuracy: 0.8889 - f1_score: 0.8265 - val_loss: 0.3826 - val_accuracy: 0.8448 - val_f1_score: 0.7550\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.2628 - accuracy: 0.8965 - f1_score: 0.8468 - val_loss: 0.3723 - val_accuracy: 0.8548 - val_f1_score: 0.7545\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.2712 - accuracy: 0.8929 - f1_score: 0.8417 - val_loss: 0.3944 - val_accuracy: 0.8317 - val_f1_score: 0.7581\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 26s 133ms/step - loss: 0.2513 - accuracy: 0.9018 - f1_score: 0.8507 - val_loss: 0.4637 - val_accuracy: 0.8145 - val_f1_score: 0.6797\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 27s 138ms/step - loss: 0.2612 - accuracy: 0.8975 - f1_score: 0.8485 - val_loss: 0.3660 - val_accuracy: 0.8438 - val_f1_score: 0.7620\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 27s 137ms/step - loss: 0.2524 - accuracy: 0.9037 - f1_score: 0.8591 - val_loss: 0.3631 - val_accuracy: 0.8508 - val_f1_score: 0.7827\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.2420 - accuracy: 0.9108 - f1_score: 0.8704 - val_loss: 0.4143 - val_accuracy: 0.8407 - val_f1_score: 0.7428\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 25s 128ms/step - loss: 0.2529 - accuracy: 0.9070 - f1_score: 0.8643 - val_loss: 0.4291 - val_accuracy: 0.8317 - val_f1_score: 0.7252\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 25s 129ms/step - loss: 0.2473 - accuracy: 0.9072 - f1_score: 0.8646 - val_loss: 0.4164 - val_accuracy: 0.8357 - val_f1_score: 0.6982\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 23s 119ms/step - loss: 0.2511 - accuracy: 0.9013 - f1_score: 0.8585 - val_loss: 0.3835 - val_accuracy: 0.8548 - val_f1_score: 0.7605\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.2455 - accuracy: 0.9053 - f1_score: 0.8655 - val_loss: 0.4172 - val_accuracy: 0.8508 - val_f1_score: 0.7368\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 25s 130ms/step - loss: 0.2470 - accuracy: 0.9060 - f1_score: 0.8636 - val_loss: 0.3925 - val_accuracy: 0.8498 - val_f1_score: 0.7588\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 25s 130ms/step - loss: 0.2444 - accuracy: 0.9077 - f1_score: 0.8646 - val_loss: 0.4518 - val_accuracy: 0.8377 - val_f1_score: 0.7116\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 27s 141ms/step - loss: 0.2508 - accuracy: 0.9078 - f1_score: 0.8652 - val_loss: 0.3864 - val_accuracy: 0.8609 - val_f1_score: 0.7667\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 25s 129ms/step - loss: 0.2946 - accuracy: 0.8840 - f1_score: 0.8349 - val_loss: 0.4380 - val_accuracy: 0.8276 - val_f1_score: 0.6939\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 26s 135ms/step - loss: 0.2760 - accuracy: 0.8950 - f1_score: 0.8476 - val_loss: 0.3561 - val_accuracy: 0.8569 - val_f1_score: 0.7904\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 25s 130ms/step - loss: 0.2390 - accuracy: 0.9122 - f1_score: 0.8734 - val_loss: 0.3894 - val_accuracy: 0.8407 - val_f1_score: 0.7455\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 25s 129ms/step - loss: 0.2375 - accuracy: 0.9087 - f1_score: 0.8640 - val_loss: 0.4144 - val_accuracy: 0.8317 - val_f1_score: 0.7121\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 25s 128ms/step - loss: 0.2359 - accuracy: 0.9122 - f1_score: 0.8714 - val_loss: 0.4132 - val_accuracy: 0.8448 - val_f1_score: 0.7184\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 25s 128ms/step - loss: 0.2357 - accuracy: 0.9117 - f1_score: 0.8697 - val_loss: 0.3997 - val_accuracy: 0.8508 - val_f1_score: 0.7517\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.2300 - accuracy: 0.9122 - f1_score: 0.8729 - val_loss: 0.4687 - val_accuracy: 0.8276 - val_f1_score: 0.6850\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 25s 127ms/step - loss: 0.2417 - accuracy: 0.9105 - f1_score: 0.8711 - val_loss: 0.4177 - val_accuracy: 0.8579 - val_f1_score: 0.7402\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.2376 - accuracy: 0.9087 - f1_score: 0.8672 - val_loss: 0.4215 - val_accuracy: 0.8488 - val_f1_score: 0.7310\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 26s 133ms/step - loss: 0.2452 - accuracy: 0.9065 - f1_score: 0.8636 - val_loss: 0.4018 - val_accuracy: 0.8498 - val_f1_score: 0.7577\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 24s 124ms/step - loss: 0.2307 - accuracy: 0.9127 - f1_score: 0.8725 - val_loss: 0.4150 - val_accuracy: 0.8438 - val_f1_score: 0.7207\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 26s 136ms/step - loss: 0.2274 - accuracy: 0.9178 - f1_score: 0.8775 - val_loss: 0.4397 - val_accuracy: 0.8266 - val_f1_score: 0.6918\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 26s 132ms/step - loss: 0.2237 - accuracy: 0.9153 - f1_score: 0.8790 - val_loss: 0.4355 - val_accuracy: 0.8448 - val_f1_score: 0.7491\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 26s 134ms/step - loss: 0.2418 - accuracy: 0.9100 - f1_score: 0.8724 - val_loss: 0.4712 - val_accuracy: 0.8296 - val_f1_score: 0.6990\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 25s 129ms/step - loss: 0.2193 - accuracy: 0.9180 - f1_score: 0.8802 - val_loss: 0.3826 - val_accuracy: 0.8589 - val_f1_score: 0.7721\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 24s 125ms/step - loss: 0.2203 - accuracy: 0.9177 - f1_score: 0.8781 - val_loss: 0.4150 - val_accuracy: 0.8306 - val_f1_score: 0.7314\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.2361 - accuracy: 0.9050 - f1_score: 0.8641 - val_loss: 0.4418 - val_accuracy: 0.8397 - val_f1_score: 0.7301\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 26s 132ms/step - loss: 0.2110 - accuracy: 0.9211 - f1_score: 0.8866 - val_loss: 0.4186 - val_accuracy: 0.8619 - val_f1_score: 0.7517\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.2131 - accuracy: 0.9215 - f1_score: 0.8881 - val_loss: 0.4670 - val_accuracy: 0.8306 - val_f1_score: 0.7309\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.2244 - accuracy: 0.9142 - f1_score: 0.8761 - val_loss: 0.4901 - val_accuracy: 0.8306 - val_f1_score: 0.7213\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 25s 131ms/step - loss: 0.2183 - accuracy: 0.9208 - f1_score: 0.8858 - val_loss: 0.3742 - val_accuracy: 0.8710 - val_f1_score: 0.8001\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 24s 123ms/step - loss: 0.2155 - accuracy: 0.9193 - f1_score: 0.8861 - val_loss: 0.4025 - val_accuracy: 0.8538 - val_f1_score: 0.7790\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 26s 137ms/step - loss: 0.2008 - accuracy: 0.9245 - f1_score: 0.8915 - val_loss: 0.3953 - val_accuracy: 0.8649 - val_f1_score: 0.7832\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 25s 130ms/step - loss: 0.2304 - accuracy: 0.9163 - f1_score: 0.8772 - val_loss: 0.4451 - val_accuracy: 0.8679 - val_f1_score: 0.7698\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 25s 130ms/step - loss: 0.2179 - accuracy: 0.9220 - f1_score: 0.8875 - val_loss: 0.4226 - val_accuracy: 0.8669 - val_f1_score: 0.7613\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 25s 128ms/step - loss: 0.2112 - accuracy: 0.9218 - f1_score: 0.8871 - val_loss: 0.4166 - val_accuracy: 0.8659 - val_f1_score: 0.7838\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.2015 - accuracy: 0.9261 - f1_score: 0.8947 - val_loss: 0.3976 - val_accuracy: 0.8639 - val_f1_score: 0.7996\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 26s 135ms/step - loss: 0.2082 - accuracy: 0.9225 - f1_score: 0.8862 - val_loss: 0.4567 - val_accuracy: 0.8488 - val_f1_score: 0.7579\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 26s 133ms/step - loss: 0.2256 - accuracy: 0.9142 - f1_score: 0.8795 - val_loss: 0.4267 - val_accuracy: 0.8599 - val_f1_score: 0.7828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test data로 평가합니다. F1 score가 평가 지표로 추가된 것을 확인할 수 있습니다.\n",
        "# 10000개의 데이터를 이용했을 때는 정확도에 비해 F1 score가 크지 않음을 알 수 있습니다. (약 0.45)\n",
        "\n",
        "model_CNN.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGeIdmlVY0zd",
        "outputId": "2b53f2ec-a212-4d81-f6a2-41ff96b9839f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 7s 117ms/step - loss: 0.5206 - accuracy: 0.8140 - f1_score: 0.4500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5206106305122375, 0.8140000104904175, 0.44999340176582336]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# F1 score가 정확도에 비해 낮은 이유를 분석하기 위해 confusion matrix를 그려봅니다.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 테스트 데이터셋에서 예측값과 실제 라벨을 가져옵니다.\n",
        "y_pred = []\n",
        "y_true = []\n",
        "for images, labels in test_data:\n",
        "    y_pred_batch = model_CNN.predict(images)\n",
        "    y_pred.extend(np.argmax(y_pred_batch, axis=1))\n",
        "    y_true.extend(np.argmax(labels, axis=1))\n",
        "\n",
        "# 혼동 행렬 계산\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# 혼동 행렬 그리기\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "\n",
        "num_classes = len(conf_matrix)\n",
        "tick_marks = np.arange(num_classes)\n",
        "plt.xticks(tick_marks, range(num_classes))\n",
        "plt.yticks(tick_marks, range(num_classes))\n",
        "\n",
        "thresh = conf_matrix.max() / 2.\n",
        "for i in range(num_classes):\n",
        "    for j in range(num_classes):\n",
        "        plt.text(j, i, format(conf_matrix[i, j], 'd'),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e1arZzuyfjVb",
        "outputId": "7eae4254-d265-4c8b-9c5c-c54b5d702102"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 964ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 169ms/step\n",
            "1/1 [==============================] - 0s 186ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 135ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 205ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 228ms/step\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "1/1 [==============================] - 0s 139ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 202ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "1/1 [==============================] - 0s 194ms/step\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 147ms/step\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 126ms/step\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "1/1 [==============================] - 0s 141ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 368ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그림을 그려보면 TP에 비해 FN이 TN, FP와 큰 차이가 나지 않아 F1 score가 작게 나옴을 알 수 있습니다.\n",
        "\n",
        "이 현상이 나온 이유는, test data와 validation data, train data set이 모두 fake : real의 비율을 3:1로 맞춰서 넣었기 때문이라 생각합니다.\n",
        "\n",
        "이러한 비율로 넣었던 이유는 저희가 원래 사용하고자 했던 데이터셋이 약 2:8의 비율로 fake 사진과 real 사진을 data set으로 사용했기 때문이었습니다.\n",
        "\n",
        "하지만 이렇게 data set을 사용하게 되면 위의 confusion matrix처럼 FN의 값이 TN, FP와 큰 차이가 나지 않게 되어, 모델의 성능이 매우 뛰어난 것이 아닌 이상, 필수불가결적으로 F1 score가 낮아질 수 밖에 없겠다는 생각이 들었습니다.\n",
        "\n",
        "기존에 저희가 사용하고자 했던 data set은 원래의 REAL 사진을 바탕으로 deepfake 기술을 사용하여 변형한 사진을 fake data로 사용하였습니다. 다양한 방법으로 fake 사진을 만들었기에, 하나의 real data가 여러 개의 fake data를 가지게 되었고, 이에 따라 어쩔 수 없이 fake data의 비중이 real data보다 클 수밖에 없었습니다.\n",
        "\n",
        "하지만 제가 사용한 data는 fake data와 real data가 서로 독립적이기에 이러한 dataset이 있다면, fake data와 real data의 비중을 1:1에 가깝게 학습하고 평가하는 것이 F1 score 값을 높일 수 있는 방법이라고 생각합니다.\n",
        "\n",
        "제가 생각한 개인적인 의견이니 틀릴 수 있습니다. 틀린 점이 있다면 알려주세요!"
      ],
      "metadata": {
        "id": "b0SzDegskwq2"
      }
    }
  ]
}